{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch",
      "provenance": [],
      "authorship_tag": "ABX9TyOGopBM4ddw/cGipwcesEMy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avenge-PRC777/ColabDeblurring/blob/master/PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bnZPWNNO2qW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc16f3a7-62cf-4791-c7f7-db92486d91ed"
      },
      "source": [
        "%cd learn-optimizer-rgdn/"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/code/learn-optimizer-rgdn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ripY7Jt-QLIm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "327edafe-0baf-445c-8347-490fe36130f1"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  imgs  LICENSE  models  options  README.md  rgdn.tr  test_entry.py  utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLVUlFMVPB1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip rgdn_dataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXik7my_tFA6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a67bbb83-0f1f-48fc-c0e6-b5a441b4b84d"
      },
      "source": [
        "# script for testing a training model\n",
        "# Please custumize the cropping and padding operations and stopping conditions as demanded.\n",
        "\n",
        "from __future__ import absolute_import, print_function\n",
        "import models\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import data\n",
        "import scipy.misc\n",
        "import time\n",
        "import scipy.io as sio\n",
        "from options.running_options import Options\n",
        "import utils\n",
        "\n",
        "#\n",
        "#opt_parser = Options()\n",
        "#opt = opt_parser.parse(is_print=True)\n",
        "use_cuda = False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "crop_size = -1 # set as 0 if input is not padded in advance\n",
        "\n",
        "# model\n",
        "trained_model = models.OptimizerRGDN(\n",
        "        40,\n",
        "        use_grad_adj=True,\n",
        "        use_grad_scaler=True,\n",
        "        use_reg=True,\n",
        "        stop_epsilon=float(\"inf\"))\n",
        "\n",
        "TrainedModelPath=\"./rgdn.tr\"\n",
        "model_para = torch.load(TrainedModelPath, map_location=device)\n",
        "trained_model.load_state_dict(model_para)\n",
        "trained_model.eval()\n",
        "trained_model.to(device)\n",
        "##\n",
        "ModelName=\"RGDNbasic\"\n",
        "model_name = ModelName\n",
        "\n",
        "# data path\n",
        "# data_root = '../'\n",
        "# dataset_name = 'rgdn_dataset'\n",
        "DataPath='../rgdn_dataset/'\n",
        "OutPath='../rgdn_results/'\n",
        "data_path = DataPath #data_root + dataset_name\n",
        "outpath = OutPath #data_root + dataset_name + '_results_' + model_name + '/'\n",
        "utils.mkdir(outpath)\n",
        "\n",
        "##\n",
        "Dataset = data.BlurryImageDataset(data_path)\n",
        "test_data_loader = DataLoader(Dataset,\n",
        "                      batch_size=1,\n",
        "                      shuffle=False,\n",
        "                      num_workers=1)\n",
        "\n",
        "sample_num = test_data_loader.__len__()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, ( (y, k, kt), sample_name) in enumerate(test_data_loader):\n",
        "        print('%d / %d, %s' % (batch_idx+1, sample_num, sample_name[0]))\n",
        "        y, kt, k = y.to(device), k.to(device), kt.to(device)\n",
        "        if(False):\n",
        "            k_size = k.size()[2]\n",
        "            padding_size = int((k_size / 2) * 1.5)\n",
        "            y = torch.nn.functional.pad(y, [padding_size, padding_size, padding_size, padding_size], mode='replicate')\n",
        "\n",
        "        start = time.time()\n",
        "        output_seq = trained_model(y, k, kt)\n",
        "        # output_len = len(output_seq)\n",
        "        x_final = output_seq[-1]\n",
        "        # print('Time {}'.format(time.time() - start))\n",
        "\n",
        "        ##\n",
        "        if (opt.ImgPad):\n",
        "            y = utils.truncate_image(y, padding_size)\n",
        "            x_final = utils.truncate_image(x_final, padding_size)\n",
        "\n",
        "        if (crop_size>0):\n",
        "            x_est_np = utils.truncate_image(x_final, crop_size)\n",
        "        elif(crop_size==0):\n",
        "            x_est_np = x_final.cpu()\n",
        "        else:\n",
        "            crt_crop_size = int(k.size()[2] /2)\n",
        "            x_est_np = utils.truncate_image(x_final, crt_crop_size)\n",
        "\n",
        "        x_est_np = utils.tensor_to_np_img(x_est_np)\n",
        "        #\n",
        "\n",
        "        x_est_np = utils.box_proj(x_est_np)\n",
        "\n",
        "        sample_name_full = sample_name[0]\n",
        "        sample_name = sample_name_full[0:len(sample_name_full) - 4]\n",
        "\n",
        "        sio.savemat(outpath + sample_name + '_estx.mat', {'x_est': x_est_np})\n",
        "        scipy.misc.imsave(outpath + sample_name + '_estx.png', x_est_np * 255)\n",
        "        torch.cuda.empty_cache()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 / 9, levin_nl001_im01_k01.mat\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}